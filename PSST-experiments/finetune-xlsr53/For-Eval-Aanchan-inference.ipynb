{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cfe6ff-841e-4f91-9ce2-11c7f0c454fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff3e7c5-7987-49b6-bb9f-9b203247b019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\"monideep2255/finetuning-xlsr-53-PSST_V7\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"monideep2255/finetuning-xlsr-53-PSST_V7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b60834-e873-4df9-9494-badf9d418b94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Wav2Vec2Processor.decode of Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0.0,\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: Wav2Vec2CTCTokenizer(name_or_path='monideep2255/finetuning-xlsr-53-PSST_V7', vocab_size=46, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<UNK>', 'pad_token': '<PAD>', 'additional_special_tokens': [AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True)]}, clean_up_tokenization_spaces=True)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2782c152-993f-4447-b64b-3096ee46f623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=1024, out_features=46, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d10bb58-1dfc-435b-a108-6042ef7d4c11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/lewis.jor/.cache/huggingface/datasets/csv/default-6df7c8ed6d6a957a/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955ad6aa5bdf4405b6099bfdc61efa95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/lewis.jor/.cache/huggingface/datasets/csv/default-5fd77a60300ece6c/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853a243d68974e8384f660a4763c681d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['utterance_id', 'session', 'test', 'prompt', 'transcript', 'correctness', 'aq_index', 'duration_frames', 'filename_old', 'filename_new'],\n",
      "    num_rows: 652\n",
      "})\n",
      "Dataset({\n",
      "    features: ['utterance_id', 'session', 'test', 'prompt', 'transcript', 'correctness', 'aq_index', 'duration_frames', 'filename_old', 'filename_new'],\n",
      "    num_rows: 341\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric, DatasetDict, Dataset, Audio\n",
    "\n",
    "# Load the datasets and observe the structure\n",
    "dataset_dict = load_dataset('csv', data_files={\n",
    "    \"test\": '/work/van-speech-nlp/PSST-experiments/psst-csv/test_utterances_excel.csv',\n",
    "})\n",
    "\n",
    "# review the datasets\n",
    "test_inferences = dataset_dict[\"test\"]\n",
    "\n",
    "dataset_dict = load_dataset('csv', data_files={\n",
    "    \"valid\": '/work/van-speech-nlp/PSST-experiments/psst-csv/valid_utterances_excel.csv',\n",
    "})\n",
    "\n",
    "# review the datasets\n",
    "valid_inferences = dataset_dict[\"valid\"]\n",
    "\n",
    "print(test_inferences)\n",
    "print(valid_inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa26363-0154-4ec7-ac04-b667568e95fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['utterance_id', 'session', 'prompt', 'transcript', 'correctness', 'filename_new'],\n",
      "    num_rows: 652\n",
      "})\n",
      "Dataset({\n",
      "    features: ['utterance_id', 'session', 'prompt', 'transcript', 'correctness', 'filename_new'],\n",
      "    num_rows: 341\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# remove columns that we do not need\n",
    "test_inferences = test_inferences.remove_columns([\"aq_index\", \"test\", \"duration_frames\",\"filename_old\"])\n",
    "valid_inferences = valid_inferences.remove_columns([\"aq_index\", \"test\", \"duration_frames\",\"filename_old\"])\n",
    "# print to verify\n",
    "print(test_inferences)\n",
    "print(valid_inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a1654e-0dc0-45b5-b617-4485cc526f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_inferences = test_inferences.cast_column(\"filename_new\", Audio(sampling_rate=16000))\n",
    "valid_inferences = valid_inferences.cast_column(\"filename_new\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db78abab-db9f-4313-87cb-225c223a3cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/work/van-speech-nlp/PSST-experiments/psst-data/psst-data-2022-03-02-full/test/audio/bnt/ACWT01a/ACWT01a-BNT06-volcano.wav',\n",
       " 'array': array([-0.00097656,  0.00195312,  0.01193237, ..., -0.00048828,\n",
       "         0.00024414,  0.00213623]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inferences[\"filename_new\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d39c34-d696-4328-9f48-de82f2aaa618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/work/van-speech-nlp/PSST-experiments/psst-data/psst-data-2022-03-02-full/valid/audio/bnt/BU01a/BU01a-BNT06-volcano.wav',\n",
       " 'array': array([-0.03860474, -0.06341553, -0.07208252, ...,  0.02603149,\n",
       "         0.03674316,  0.03723145]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_inferences[\"filename_new\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4dbd5ab-5305-49fc-85b2-107860510760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/lewis.jor/.cache/huggingface/datasets/csv/default-6df7c8ed6d6a957a/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-d3332a8dbee6835d_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/lewis.jor/.cache/huggingface/datasets/csv/default-5fd77a60300ece6c/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-121dbdd23bf3822b_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "def prepare_references_dataset(batch):\n",
    "    # load the audio data into batch\n",
    "    audio = batch[\"filename_new\"]\n",
    "\n",
    "    # extract the values from the audio files\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "\n",
    "    # encode the transcript to the label ids\n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"transcript\"]).input_ids\n",
    "    \n",
    "    # remove all columns except for 'transcript'\n",
    "    batch = {key: batch[key] for key in batch.keys() if key == 'transcript'}\n",
    "    \n",
    "    return batch\n",
    "\n",
    "test_inferences = test_inferences.map(prepare_references_dataset, num_proc=4)\n",
    "valid_inferences = valid_inferences.map(prepare_references_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1314e088-7e71-429f-94b0-b0898e821e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_inference_data = test_inferences[20:50]\n",
    "# sample_inference_data['input_values'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc5d501-0b3a-4060-978a-bdb63bcf2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.decoder = {24: '<???>',\n",
    " 3: '<PAD>',\n",
    " 2: '<SIL>',\n",
    " 18: '<SPN>',\n",
    " 19: '<UNK>',\n",
    " 1: ' AA ',\n",
    " 8: '  AE',\n",
    " 6: ' AH ',\n",
    " 36: ' AO ',\n",
    " 33: ' AW ',\n",
    " 17: ' AY ',\n",
    " 20: ' B ',\n",
    " 43: ' CH ',\n",
    " 35: ' D ',\n",
    " 42: ' DH ',\n",
    " 10: ' DX ',\n",
    " 7: ' EH ',\n",
    " 12: ' ER ',\n",
    " 44: ' EY ',\n",
    " 27: ' F ',\n",
    " 40: ' G ',\n",
    " 9: ' HH ',\n",
    " 41: ' IH ',\n",
    " 14: ' IY ',\n",
    " 28: ' JH ',\n",
    " 21: ' K ',\n",
    " 22: ' L ',\n",
    " 37: ' M ',\n",
    " 0: ' N ',\n",
    " 25: ' NG ',\n",
    " 16: ' OW ',\n",
    " 15: ' OY ',\n",
    " 32: ' P ',\n",
    " 45: ' R ',\n",
    " 38: ' S ',\n",
    " 29: ' SH ',\n",
    " 5: ' T ',\n",
    " 31: ' TH ',\n",
    " 11: ' UH ',\n",
    " 4: ' UW ',\n",
    " 34: ' V ',\n",
    " 30: ' W ',\n",
    " 39: ' Y ',\n",
    " 13: ' Z ',\n",
    " 26: ' ZH ',\n",
    " 23: '|'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac5b07a-8c96-487e-8e87-08afed34f406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# print(test_inferences['input_values'][0])\n",
    "# Generate predictions for each sample\n",
    "\n",
    "def predictions_list(dataset):\n",
    "    res = []\n",
    "    for i in range(len(dataset['transcript'])):\n",
    "        \n",
    "        input_values = np.array(dataset['input_values'][i])\n",
    "        sampling_rate = dataset['input_length'][i]\n",
    "\n",
    "        # Resample the input speech to match the model's sampling rate\n",
    "        input_values = librosa.resample(input_values, orig_sr=sampling_rate, target_sr=16000)\n",
    "        input_values = processor(input_values, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "        input_values = input_values.to(device)  # Move input to the same device as the model\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(input_values).logits\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        #print(predicted_ids)\n",
    "        transcription = processor.decode(predicted_ids[0], clean_up_tokenization_spaces=False)\n",
    "        print(predicted_ids[0])       \n",
    "        prediction = transcription.lstrip().rstrip().replace('  ',' ').replace('\\t',' ')\n",
    "        \n",
    "        res.append(prediction)\n",
    "        \n",
    "        reference_transcription = dataset['transcript'][i]\n",
    "        print(\"Utterance Id:\", dataset['utterance_id'][i])\n",
    "        print(\"Reference:\", reference_transcription)\n",
    "        print(\"Prediction:\", prediction)\n",
    "        print(\"---\")\n",
    "#     return res\n",
    "\n",
    "        # print(\"Reference:\", reference_transcription)\n",
    "        # print(\"Prediction:\", transcription.lstrip().rstrip().replace('  ',' ').replace('\\t',' '))\n",
    "        # print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71aeb383-6f81-4458-9b2f-dde6eea7d550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(sample_inference_data['transcript']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e53307c-6c6a-4b5e-a2ca-cf3bb995504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23,  3,  3,  5,  6,  3,  3,  3,\n",
      "         3,  3,  3,  3, 23,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  5,  3,  3,  3,  3,  3,  3,  3, 23,  3, 23], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT09-watch\n",
      "Reference: K AE T AA M K AE T AA M\n",
      "Prediction: T AH  T\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3, 39,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  1,  3,  3,  3,  3,  3,  0,  6,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT10-give\n",
      "Reference: AH G EH DX IH NG AH P R EH Z IH N\n",
      "Prediction: Y AA N AH\n",
      "---\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT11-swim\n",
      "Reference: IH N D AH M B IY AH M <spn> <sil> IH T S OW P N OW AH M <spn> <sil> IH T S M B IH M IH NG S W IH M IH NG\n",
      "Prediction: \n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3, 32, 23, 45, 45, 16,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3, 41, 41, 25,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         6,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT12-stir\n",
      "Reference: D R OY NG Y ER\n",
      "Prediction: P  R OW IH NG AH\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3, 32, 32, 41,  0,  0,  0,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3, 43, 41, 41, 25, 25,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT13-pinch\n",
      "Reference: P IH N CH IH NG\n",
      "Prediction: P IH N CH IH NG\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23, 23], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT14-crawl\n",
      "Reference: AH B EY B IY D R AO L IH NG N OW AY D OW N OW AH M\n",
      "Prediction: \n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3, 16,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  6,  3,  3,  3,  3,  3,  3,  3, 32,  1,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3, 38, 23, 23,  3,  3,  3,  5, 23, 23,  3], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT15-deliver\n",
      "Reference: M UW V IH NG Y AO R P AE K IH JH\n",
      "Prediction: OW AH P AA S  T\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  6,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3, 42,  8,  3,  3,  3,  3,  3, 23,  3,  3,  3,  1,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23, 23], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT16-pour\n",
      "Reference: DH EY R D R IH NG K IH NG W AA DX ER\n",
      "Prediction: AH DH  AE AA\n",
      "---\n",
      "tensor([ 3,  3,  3,  3, 27,  1, 45, 45,  3, 23,  3,  3,  3,  5,  5,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23,  3,  3,  3,\n",
      "        37,  6,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT17-howl\n",
      "Reference: L UH K IH NG AE D AH M UW N\n",
      "Prediction: F AA R  T  M AH\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  9, 33,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3, 22,  3, 23,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT18-throw\n",
      "Reference: AH TH R OW IH NG IH T\n",
      "Prediction: HH AW L\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3, 45, 45, 33,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 22,\n",
      "        41, 25,  3, 23,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT19-bite\n",
      "Reference: G IH T Y ER M AH D IH NG IH T\n",
      "Prediction: R AW L IH NG\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  6,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3, 22,  1,  3,  3,  3,  3,  3, 38,  6,  6,  3,  3,\n",
      "        23, 23,  3, 37, 17,  3,  3,  3,  3,  3,  3, 23, 23], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT20-shove\n",
      "Reference: OW P UH SH IH NG Y ER\n",
      "Prediction: AH L AA S AH  M AY\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 22, 41,  3,\n",
      "        27, 27,  3, 23, 23,  3,  5, 23,  3, 45, 41, 41, 41, 25, 25,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT21-tickle\n",
      "Reference: T IH K AH L IH NG\n",
      "Prediction: L IH F  T  R IH NG\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  8,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3, 23, 23, 23, 23], device='cuda:0')\n",
      "Utterance Id: ACWT01a-VNT22-shave\n",
      "Reference: B R AH SH IH NG Y AO R T IY TH M AO R OW G ER SH EY V IH NG\n",
      "Prediction: AE\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3, 21, 21, 16, 37, 37,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-BNT02-comb\n",
      "Reference: K OW M\n",
      "Prediction: K OW M\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  5,  5,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 32, 41,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT01-cut\n",
      "Reference: AH UW S IH S IH Z ER Z\n",
      "Prediction: T P IH\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         5, 23, 23,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3, 23,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT02-bark\n",
      "Reference: UW Y EH S Y AH Y EH S IY OW Y EH S\n",
      "Prediction: T\n",
      "---\n",
      "tensor([ 3,  3, 37,  7,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT03-put\n",
      "Reference: AH AY D OW N OW\n",
      "Prediction: M EH\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  5,  3,  3,  3,  3,  3,  5,  5,\n",
      "        23,  3,  3,  3, 32, 32,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT04-send\n",
      "Reference: Y EH AH Y AH M Y EH S Y AE OW Y EH S Y EH S\n",
      "Prediction: T T  P\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3, 20,  8,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  5,  6,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT05-drive\n",
      "Reference: AE AY D OW N OW AH M\n",
      "Prediction: B  AE T AH\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 21,  6,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  5, 23, 23,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT06-wash\n",
      "Reference: AH AH M S IY AY\n",
      "Prediction: K AH T\n",
      "---\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT07-read\n",
      "Reference: Y AH Y EH S AH HH AH Y EH S AH Y AE\n",
      "Prediction: \n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 16,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3, 17,  3,  3,  3,  3,  3,  3, 22,  8,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  6,  0,  0, 23], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT09-watch\n",
      "Reference: N N AH TH IH NG\n",
      "Prediction: OW AY L  AE AH N\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3, 23,  3,  5,  5, 23, 23], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT10-give\n",
      "Reference: IH OW AH N AH TH IH NG N AH TH IH NG N OW\n",
      "Prediction: T\n",
      "---\n",
      "tensor([ 3,  3,  3,  5,  3,  3,  3,  3,  3,  3,  5,  5,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  5, 23,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  5, 23, 23, 23,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT11-swim\n",
      "Reference: AH OW AH M M AY D AH SH IY Z AH S AH AH AY D OW N N OW\n",
      "Prediction: T T T  T\n",
      "---\n",
      "tensor([ 3,  3,  3, 41,  5,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3, 43,  6,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 10,\n",
      "        41, 41, 25,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT12-stir\n",
      "Reference: HH IY CH ER N IH NG\n",
      "Prediction: IH T CH AH DX IH NG\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  5,  5, 23, 23,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT13-pinch\n",
      "Reference: OW HH AH IY Y AE IY Y AE IH Y AE <spn> OW N OW AH\n",
      "Prediction: T\n",
      "---\n",
      "tensor([ 3,  5,  5,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  5,\n",
      "         5,  3,  3,  3,  3, 22, 17,  3, 23,  3, 21, 41, 41,  3,  3,  3,  3,  3,\n",
      "         3,  3,  5,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT14-crawl\n",
      "Reference: OW S IH T AH M EY AH K AH M IY R Y AE <spn>\n",
      "Prediction: T T L AY  K IH T\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 38,  3, 23,  3,  3,  3, 32,  3,\n",
      "        23,  3,  3,  3,  3,  5,  5,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 23, 23, 23], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT15-deliver\n",
      "Reference: AH OW Y AE OW AH SH UW T AH M <spn> M AY D OW N N OW\n",
      "Prediction: S  P  T\n",
      "---\n",
      "tensor([ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  5,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  5,  5, 41,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3, 23, 23,  3,  5, 23, 23,  3], device='cuda:0')\n",
      "Utterance Id: ACWT08a-VNT16-pour\n",
      "Reference: OW AH AH AY D OW N OW AH\n",
      "Prediction: T T IH  T\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_predictions_list = predictions_list(sample_inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c2a28f6-34e0-4df2-a0fc-753fcec0b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_predictions_list = predictions_list(valid_inferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba259edf-04ef-47c6-9cc4-c947d494e273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'K IH K  K AH L IH NG', 'SH EY V IH NG', 'HH AW S', 'K OW M', 'T IH NG K AH S', '', 'B AH T  S', '']\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ed2687b-9b8b-4079-a940-0978674a5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_tsv(dataset, dataset_predictions):\n",
    "    file_name = \"temp-decoded-test.tsv\"\n",
    "    with open(file_name, \"w\") as f:\n",
    "        writer = csv.writer(f, dialect=csv.excel_tab)\n",
    "        writer.writerow((\"utterance_id\", \"asr_transcript\"))\n",
    "        for i in range(len(dataset)):\n",
    "            utterance_id = dataset['utterance_id'][i]\n",
    "            writer.writerow((utterance_id, dataset_predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deaccd07-84df-4662-b9f6-f01ec75beb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv(sample_inference_data, test_predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b54112-093d-48f7-a9ed-3671780b31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_tsv(valid_predictions_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1907227-8f26-44e3-b319-a3873c17ccfa",
   "metadata": {},
   "source": [
    "processor.tokenizer.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7fd00-f62d-4a17-9f16-e218606d5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.encoder['AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c769c0-1622-4e7f-a202-6488ca141799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor.tokenizer.decoder = {24: '<???>',\n",
    " 3: '<PAD>',\n",
    " 2: '<SIL>',\n",
    " 18: '<SPN>',\n",
    " 19: '<UNK>',\n",
    " 1: ' AA ',\n",
    " 8: '  AE',\n",
    " 6: ' AH ',\n",
    " 36: ' AO ',\n",
    " 33: ' AW ',\n",
    " 17: ' AY ',\n",
    " 20: ' B ',\n",
    " 43: ' CH ',\n",
    " 35: ' D ',\n",
    " 42: ' DH ',\n",
    " 10: ' DX ',\n",
    " 7: ' EH ',\n",
    " 12: ' ER ',\n",
    " 44: ' EY ',\n",
    " 27: ' F ',\n",
    " 40: ' G ',\n",
    " 9: ' HH ',\n",
    " 41: ' IH ',\n",
    " 14: ' IY ',\n",
    " 28: ' JH ',\n",
    " 21: ' K ',\n",
    " 22: ' L ',\n",
    " 37: ' M ',\n",
    " 0: ' N ',\n",
    " 25: ' NG ',\n",
    " 16: ' OW ',\n",
    " 15: ' OY ',\n",
    " 32: ' P ',\n",
    " 45: ' R ',\n",
    " 38: ' S ',\n",
    " 29: ' SH ',\n",
    " 5: ' T ',\n",
    " 31: ' TH ',\n",
    " 11: ' UH ',\n",
    " 4: ' UW ',\n",
    " 34: ' V ',\n",
    " 30: ' W ',\n",
    " 39: ' Y ',\n",
    " 13: ' Z ',\n",
    " 26: ' ZH ',\n",
    " 23: '|'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da92d0-5670-42fe-9a3f-32937f622a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
